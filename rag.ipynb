{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m pytesseract\u001b[38;5;241m.\u001b[39mpytesseract\u001b[38;5;241m.\u001b[39mtesseract_cmd \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mProgram Files\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mTesseract-OCR\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtesseract\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Adjust to your path\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Initialize Embedding Model and Chroma\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m embedding_model \u001b[38;5;241m=\u001b[39m SentenceTransformer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall-mpnet-base-v2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     23\u001b[0m chroma_ef \u001b[38;5;241m=\u001b[39m embedding_functions\u001b[38;5;241m.\u001b[39mSentenceTransformerEmbeddingFunction(model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall-mpnet-base-v2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Create chroma directory if it doesn't exist\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\savit\\anaconda3\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:301\u001b[0m, in \u001b[0;36mSentenceTransformer.__init__\u001b[1;34m(self, model_name_or_path, modules, device, prompts, default_prompt_name, similarity_fn_name, cache_folder, trust_remote_code, revision, local_files_only, token, use_auth_token, truncate_dim, model_kwargs, tokenizer_kwargs, config_kwargs, model_card_data, backend)\u001b[0m\n\u001b[0;32m    297\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m model_name_or_path \u001b[38;5;129;01mand\u001b[39;00m model_name_or_path\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m basic_transformer_models:\n\u001b[0;32m    298\u001b[0m         \u001b[38;5;66;03m# A model from sentence-transformers\u001b[39;00m\n\u001b[0;32m    299\u001b[0m         model_name_or_path \u001b[38;5;241m=\u001b[39m __MODEL_HUB_ORGANIZATION__ \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m model_name_or_path\n\u001b[1;32m--> 301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_sentence_transformer_model(\n\u001b[0;32m    302\u001b[0m     model_name_or_path,\n\u001b[0;32m    303\u001b[0m     token,\n\u001b[0;32m    304\u001b[0m     cache_folder\u001b[38;5;241m=\u001b[39mcache_folder,\n\u001b[0;32m    305\u001b[0m     revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[0;32m    306\u001b[0m     local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[0;32m    307\u001b[0m ):\n\u001b[0;32m    308\u001b[0m     modules, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_sbert_model(\n\u001b[0;32m    309\u001b[0m         model_name_or_path,\n\u001b[0;32m    310\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    317\u001b[0m         config_kwargs\u001b[38;5;241m=\u001b[39mconfig_kwargs,\n\u001b[0;32m    318\u001b[0m     )\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\savit\\anaconda3\\Lib\\site-packages\\sentence_transformers\\util.py:1319\u001b[0m, in \u001b[0;36mis_sentence_transformer_model\u001b[1;34m(model_name_or_path, token, cache_folder, revision, local_files_only)\u001b[0m\n\u001b[0;32m   1298\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_sentence_transformer_model\u001b[39m(\n\u001b[0;32m   1299\u001b[0m     model_name_or_path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   1300\u001b[0m     token: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1303\u001b[0m     local_files_only: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1304\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m   1305\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1306\u001b[0m \u001b[38;5;124;03m    Checks if the given model name or path corresponds to a SentenceTransformer model.\u001b[39;00m\n\u001b[0;32m   1307\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1316\u001b[0m \u001b[38;5;124;03m        bool: True if the model is a SentenceTransformer model, False otherwise.\u001b[39;00m\n\u001b[0;32m   1317\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   1318\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(\n\u001b[1;32m-> 1319\u001b[0m         load_file_path(\n\u001b[0;32m   1320\u001b[0m             model_name_or_path,\n\u001b[0;32m   1321\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodules.json\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1322\u001b[0m             token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[0;32m   1323\u001b[0m             cache_folder\u001b[38;5;241m=\u001b[39mcache_folder,\n\u001b[0;32m   1324\u001b[0m             revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[0;32m   1325\u001b[0m             local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[0;32m   1326\u001b[0m         )\n\u001b[0;32m   1327\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\savit\\anaconda3\\Lib\\site-packages\\sentence_transformers\\util.py:1359\u001b[0m, in \u001b[0;36mload_file_path\u001b[1;34m(model_name_or_path, filename, token, cache_folder, revision, local_files_only)\u001b[0m\n\u001b[0;32m   1357\u001b[0m \u001b[38;5;66;03m# If file is remote\u001b[39;00m\n\u001b[0;32m   1358\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1359\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hf_hub_download(\n\u001b[0;32m   1360\u001b[0m         model_name_or_path,\n\u001b[0;32m   1361\u001b[0m         filename\u001b[38;5;241m=\u001b[39mfilename,\n\u001b[0;32m   1362\u001b[0m         revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[0;32m   1363\u001b[0m         library_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentence-transformers\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1364\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[0;32m   1365\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_folder,\n\u001b[0;32m   1366\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[0;32m   1367\u001b[0m     )\n\u001b[0;32m   1368\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1369\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\savit\\anaconda3\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\savit\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:862\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[1;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[0;32m    842\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_local_dir(\n\u001b[0;32m    843\u001b[0m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[0;32m    844\u001b[0m         local_dir\u001b[38;5;241m=\u001b[39mlocal_dir,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    859\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[0;32m    860\u001b[0m     )\n\u001b[0;32m    861\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_cache_dir(\n\u001b[0;32m    863\u001b[0m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[0;32m    864\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[0;32m    865\u001b[0m         \u001b[38;5;66;03m# File info\u001b[39;00m\n\u001b[0;32m    866\u001b[0m         repo_id\u001b[38;5;241m=\u001b[39mrepo_id,\n\u001b[0;32m    867\u001b[0m         filename\u001b[38;5;241m=\u001b[39mfilename,\n\u001b[0;32m    868\u001b[0m         repo_type\u001b[38;5;241m=\u001b[39mrepo_type,\n\u001b[0;32m    869\u001b[0m         revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[0;32m    870\u001b[0m         \u001b[38;5;66;03m# HTTP info\u001b[39;00m\n\u001b[0;32m    871\u001b[0m         endpoint\u001b[38;5;241m=\u001b[39mendpoint,\n\u001b[0;32m    872\u001b[0m         etag_timeout\u001b[38;5;241m=\u001b[39metag_timeout,\n\u001b[0;32m    873\u001b[0m         headers\u001b[38;5;241m=\u001b[39mhf_headers,\n\u001b[0;32m    874\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[0;32m    875\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[0;32m    876\u001b[0m         \u001b[38;5;66;03m# Additional options\u001b[39;00m\n\u001b[0;32m    877\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[0;32m    878\u001b[0m         force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[0;32m    879\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\savit\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:925\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[1;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[0;32m    921\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m pointer_path\n\u001b[0;32m    923\u001b[0m \u001b[38;5;66;03m# Try to get metadata (etag, commit_hash, url, size) from the server.\u001b[39;00m\n\u001b[0;32m    924\u001b[0m \u001b[38;5;66;03m# If we can't, a HEAD request error is returned.\u001b[39;00m\n\u001b[1;32m--> 925\u001b[0m (url_to_download, etag, commit_hash, expected_size, head_call_error) \u001b[38;5;241m=\u001b[39m _get_metadata_or_catch_error(\n\u001b[0;32m    926\u001b[0m     repo_id\u001b[38;5;241m=\u001b[39mrepo_id,\n\u001b[0;32m    927\u001b[0m     filename\u001b[38;5;241m=\u001b[39mfilename,\n\u001b[0;32m    928\u001b[0m     repo_type\u001b[38;5;241m=\u001b[39mrepo_type,\n\u001b[0;32m    929\u001b[0m     revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[0;32m    930\u001b[0m     endpoint\u001b[38;5;241m=\u001b[39mendpoint,\n\u001b[0;32m    931\u001b[0m     proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[0;32m    932\u001b[0m     etag_timeout\u001b[38;5;241m=\u001b[39metag_timeout,\n\u001b[0;32m    933\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    934\u001b[0m     token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[0;32m    935\u001b[0m     local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[0;32m    936\u001b[0m     storage_folder\u001b[38;5;241m=\u001b[39mstorage_folder,\n\u001b[0;32m    937\u001b[0m     relative_filename\u001b[38;5;241m=\u001b[39mrelative_filename,\n\u001b[0;32m    938\u001b[0m )\n\u001b[0;32m    940\u001b[0m \u001b[38;5;66;03m# etag can be None for several reasons:\u001b[39;00m\n\u001b[0;32m    941\u001b[0m \u001b[38;5;66;03m# 1. we passed local_files_only.\u001b[39;00m\n\u001b[0;32m    942\u001b[0m \u001b[38;5;66;03m# 2. we don't have a connection\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;66;03m# If the specified revision is a commit hash, look inside \"snapshots\".\u001b[39;00m\n\u001b[0;32m    949\u001b[0m \u001b[38;5;66;03m# If the specified revision is a branch or tag, look inside \"refs\".\u001b[39;00m\n\u001b[0;32m    950\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m head_call_error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    951\u001b[0m     \u001b[38;5;66;03m# Couldn't make a HEAD call => let's try to find a local file\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\savit\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:1376\u001b[0m, in \u001b[0;36m_get_metadata_or_catch_error\u001b[1;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[0;32m   1374\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1375\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1376\u001b[0m         metadata \u001b[38;5;241m=\u001b[39m get_hf_file_metadata(\n\u001b[0;32m   1377\u001b[0m             url\u001b[38;5;241m=\u001b[39murl, proxies\u001b[38;5;241m=\u001b[39mproxies, timeout\u001b[38;5;241m=\u001b[39metag_timeout, headers\u001b[38;5;241m=\u001b[39mheaders, token\u001b[38;5;241m=\u001b[39mtoken\n\u001b[0;32m   1378\u001b[0m         )\n\u001b[0;32m   1379\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n\u001b[0;32m   1380\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m storage_folder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m relative_filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1381\u001b[0m             \u001b[38;5;66;03m# Cache the non-existence of the file\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\savit\\anaconda3\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\savit\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:1296\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[1;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[0;32m   1293\u001b[0m hf_headers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccept-Encoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midentity\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# prevent any compression => we want to know the real size of the file\u001b[39;00m\n\u001b[0;32m   1295\u001b[0m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[1;32m-> 1296\u001b[0m r \u001b[38;5;241m=\u001b[39m _request_wrapper(\n\u001b[0;32m   1297\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHEAD\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1298\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m   1299\u001b[0m     headers\u001b[38;5;241m=\u001b[39mhf_headers,\n\u001b[0;32m   1300\u001b[0m     allow_redirects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1301\u001b[0m     follow_relative_redirects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   1302\u001b[0m     proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[0;32m   1303\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m   1304\u001b[0m )\n\u001b[0;32m   1305\u001b[0m hf_raise_for_status(r)\n\u001b[0;32m   1307\u001b[0m \u001b[38;5;66;03m# Return\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\savit\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:280\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[1;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;66;03m# Recursively follow relative redirects\u001b[39;00m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[1;32m--> 280\u001b[0m     response \u001b[38;5;241m=\u001b[39m _request_wrapper(\n\u001b[0;32m    281\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m    282\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m    283\u001b[0m         follow_relative_redirects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    284\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m    285\u001b[0m     )\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[0;32m    288\u001b[0m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m300\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m399\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\savit\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:303\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[1;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[0;32m    300\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[0;32m    302\u001b[0m \u001b[38;5;66;03m# Perform request and return if status_code is not in the retry list.\u001b[39;00m\n\u001b[1;32m--> 303\u001b[0m response \u001b[38;5;241m=\u001b[39m get_session()\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m    304\u001b[0m hf_raise_for_status(response)\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\savit\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\savit\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\savit\\anaconda3\\Lib\\site-packages\\huggingface_hub\\utils\\_http.py:96\u001b[0m, in \u001b[0;36mUniqueRequestIdAdapter.send\u001b[1;34m(self, request, *args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSend: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_curlify(request)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mRequestException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     request_id \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(X_AMZN_TRACE_ID)\n",
      "File \u001b[1;32mc:\\Users\\savit\\anaconda3\\Lib\\site-packages\\requests\\adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[0;32m    668\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    669\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m    670\u001b[0m         body\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mbody,\n\u001b[0;32m    671\u001b[0m         headers\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    672\u001b[0m         redirect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    673\u001b[0m         assert_same_host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    674\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    675\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    676\u001b[0m         retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries,\n\u001b[0;32m    677\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    678\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    679\u001b[0m     )\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[1;32mc:\\Users\\savit\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    784\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    788\u001b[0m     conn,\n\u001b[0;32m    789\u001b[0m     method,\n\u001b[0;32m    790\u001b[0m     url,\n\u001b[0;32m    791\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    792\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    793\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    794\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    795\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[0;32m    796\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[0;32m    797\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    798\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    799\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    800\u001b[0m )\n\u001b[0;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[0;32m    803\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\savit\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:464\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    462\u001b[0m     \u001b[38;5;66;03m# Trigger any extra validation we need to do.\u001b[39;00m\n\u001b[0;32m    463\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 464\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_conn(conn)\n\u001b[0;32m    465\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    466\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mconn\u001b[38;5;241m.\u001b[39mtimeout)\n",
      "File \u001b[1;32mc:\\Users\\savit\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1093\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;66;03m# Force connect early to allow us to validate the connection.\u001b[39;00m\n\u001b[0;32m   1092\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_closed:\n\u001b[1;32m-> 1093\u001b[0m     conn\u001b[38;5;241m.\u001b[39mconnect()\n\u001b[0;32m   1095\u001b[0m \u001b[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[39;00m\n\u001b[0;32m   1096\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_verified \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mproxy_is_verified:\n",
      "File \u001b[1;32mc:\\Users\\savit\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py:704\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    703\u001b[0m     sock: socket\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;241m|\u001b[39m ssl\u001b[38;5;241m.\u001b[39mSSLSocket\n\u001b[1;32m--> 704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m sock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_conn()\n\u001b[0;32m    705\u001b[0m     server_hostname: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n\u001b[0;32m    706\u001b[0m     tls_in_tls \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\savit\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py:198\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Establish a socket connection and set nodelay settings on it.\u001b[39;00m\n\u001b[0;32m    194\u001b[0m \n\u001b[0;32m    195\u001b[0m \u001b[38;5;124;03m:return: New socket connection.\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 198\u001b[0m     sock \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39mcreate_connection(\n\u001b[0;32m    199\u001b[0m         (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dns_host, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport),\n\u001b[0;32m    200\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout,\n\u001b[0;32m    201\u001b[0m         source_address\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_address,\n\u001b[0;32m    202\u001b[0m         socket_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msocket_options,\n\u001b[0;32m    203\u001b[0m     )\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NameResolutionError(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost, \u001b[38;5;28mself\u001b[39m, e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\savit\\anaconda3\\Lib\\site-packages\\urllib3\\util\\connection.py:60\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mUnicodeError\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LocationParseError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhost\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, label empty or too long\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgetaddrinfo(host, port, family, socket\u001b[38;5;241m.\u001b[39mSOCK_STREAM):\n\u001b[0;32m     61\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n\u001b[0;32m     62\u001b[0m     sock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\savit\\anaconda3\\Lib\\socket.py:976\u001b[0m, in \u001b[0;36mgetaddrinfo\u001b[1;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# We override this function since we want to translate the numeric family\u001b[39;00m\n\u001b[0;32m    974\u001b[0m \u001b[38;5;66;03m# and socket type values to enum constants.\u001b[39;00m\n\u001b[0;32m    975\u001b[0m addrlist \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m _socket\u001b[38;5;241m.\u001b[39mgetaddrinfo(host, port, family, \u001b[38;5;28mtype\u001b[39m, proto, flags):\n\u001b[0;32m    977\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n\u001b[0;32m    978\u001b[0m     addrlist\u001b[38;5;241m.\u001b[39mappend((_intenum_converter(af, AddressFamily),\n\u001b[0;32m    979\u001b[0m                      _intenum_converter(socktype, SocketKind),\n\u001b[0;32m    980\u001b[0m                      proto, canonname, sa))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pptx import Presentation\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import io\n",
    "import google.generativeai as genai\n",
    "import json\n",
    "import PyPDF2\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "import re\n",
    "import os\n",
    "\n",
    "# Configure API key\n",
    "genai.configure(api_key=\"AIzaSyAEdj0FwtMdMyqiNAXs6Gz0HrZ0KIe6s4Q\")  # Replace with your actual API key\n",
    "model = genai.GenerativeModel('gemini-2.0-flash')\n",
    "\n",
    "# Configure Tesseract path if needed\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract'  # Adjust to your path\n",
    "\n",
    "# Initialize Embedding Model and Chroma\n",
    "embedding_model = SentenceTransformer('all-mpnet-base-v2')\n",
    "chroma_ef = embedding_functions.SentenceTransformerEmbeddingFunction(model_name=\"all-mpnet-base-v2\")\n",
    "\n",
    "# Create chroma directory if it doesn't exist\n",
    "os.makedirs(\"./chroma_db\", exist_ok=True)\n",
    "client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "collection = client.get_or_create_collection(\"chemistry_collection\", embedding_function=chroma_ef)\n",
    "\n",
    "def extract_page_data(page, page_type):\n",
    "    \"\"\"Extracts text and image captions from a page (PPT or PDF).\"\"\"\n",
    "    if page_type == \"ppt\":\n",
    "        slide_data = {\"slide_text\": [], \"image_captions\": []}\n",
    "        for shape in page.shapes:\n",
    "            if shape.has_text_frame:\n",
    "                for paragraph in shape.text_frame.paragraphs:\n",
    "                    slide_data[\"slide_text\"].append(paragraph.text)\n",
    "            elif shape.has_picture:\n",
    "                try:\n",
    "                    image_bytes = shape.image.blob  # Fixed: Changed page.image to shape.image\n",
    "                    image = Image.open(io.BytesIO(image_bytes))\n",
    "                    text = pytesseract.image_to_string(image)\n",
    "                    slide_data[\"image_captions\"].append(text)\n",
    "                except Exception as e_image:\n",
    "                    print(f\"Error processing image: {e_image}\")\n",
    "        return slide_data\n",
    "\n",
    "    elif page_type == \"pdf\":\n",
    "        page_text = page.extract_text()\n",
    "        return {\"slide_text\": [page_text], \"image_captions\": []}  # PDFs don't have images in the same way.\n",
    "\n",
    "    else:\n",
    "        return {\"slide_text\": [], \"image_captions\": []}\n",
    "\n",
    "def process_ppt_pages(ppt_file_path):\n",
    "    \"\"\"Processes each page of a PPT and extracts data.\"\"\"\n",
    "    try:\n",
    "        presentation = Presentation(ppt_file_path)\n",
    "        page_data = []\n",
    "        for i, slide in enumerate(presentation.slides):\n",
    "            data = extract_page_data(slide, \"ppt\")\n",
    "            page_data.append({\"page_number\": i + 1, \"data\": data, \"page_type\": \"ppt\"})\n",
    "        return page_data\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing PPT: {e}\")\n",
    "        return []\n",
    "\n",
    "def process_pdf_pages(pdf_file_path):\n",
    "    \"\"\"Processes each page of a PDF and extracts data.\"\"\"\n",
    "    try:\n",
    "        with open(pdf_file_path, \"rb\") as file:\n",
    "            pdf_reader = PyPDF2.PdfReader(file)\n",
    "            page_data = []\n",
    "            for i, page in enumerate(pdf_reader.pages):\n",
    "                data = extract_page_data(page, \"pdf\")\n",
    "                page_data.append({\"page_number\": i + 1, \"data\": data, \"page_type\": \"pdf\"})\n",
    "        return page_data\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing PDF: {e}\")\n",
    "        return []\n",
    "\n",
    "def process_files(file_path):\n",
    "    \"\"\"Processes either a PPT or PDF file based on its extension.\"\"\"\n",
    "    if file_path.lower().endswith(\".pptx\"):\n",
    "        return process_ppt_pages(file_path)\n",
    "    elif file_path.lower().endswith(\".pdf\"):\n",
    "        return process_pdf_pages(file_path)\n",
    "    else:\n",
    "        print(\"Unsupported file type.\")\n",
    "        return []\n",
    "\n",
    "def extract_chemistry_qa_from_page(page_data):\n",
    "    \"\"\"Extracts chemistry questions and answers from a page's text using Gemini.\"\"\"\n",
    "    slide_text = \"\\n\".join(page_data[\"slide_text\"])\n",
    "    image_captions = \"\\n\".join(page_data[\"image_captions\"])\n",
    "    combined_text = slide_text + \"\\n\" + image_captions\n",
    "\n",
    "    if not combined_text.strip():\n",
    "        return None\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Extract chemistry questions and answers from the following text. \n",
    "    Format your response as a JSON object with the following structure:\n",
    "    {{\n",
    "        \"questions\": [\n",
    "            {{\n",
    "                \"question_text\": \"Full text of the question\",\n",
    "                \"options\": {{\n",
    "                    \"A\": \"Text of option A\",\n",
    "                    \"B\": \"Text of option B\",\n",
    "                    \"C\": \"Text of option C\",\n",
    "                    \"D\": \"Text of option D\"\n",
    "                }},\n",
    "                \"correct_answer\": \"Letter of the correct option (A, B, C, or D)\",\n",
    "                \"explanation\": \"Explanation of the answer\"\n",
    "            }},\n",
    "            ...\n",
    "        ]\n",
    "    }}\n",
    "    \n",
    "    If there are no clear questions and answers, return an empty questions array.\n",
    "    If options are not lettered, assign them letters in order.\n",
    "    \n",
    "    Text: {combined_text}\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = model.generate_content(prompt)\n",
    "        response_text = response.text\n",
    "        \n",
    "        # Try to parse as JSON\n",
    "        try:\n",
    "            # Find JSON content within response (in case there's extra text)\n",
    "            json_match = re.search(r'```json\\s*([\\s\\S]*?)\\s*```', response_text)\n",
    "            if json_match:\n",
    "                json_str = json_match.group(1)\n",
    "            else:\n",
    "                json_str = response_text\n",
    "                \n",
    "            # Clean up any markdown formatting\n",
    "            json_str = re.sub(r'```.*?```', '', json_str, flags=re.DOTALL)\n",
    "            \n",
    "            # Parse the JSON\n",
    "            result = json.loads(json_str)\n",
    "            return result\n",
    "        except json.JSONDecodeError:\n",
    "            # If parsing fails, try to identify and fix common JSON issues\n",
    "            cleaned_text = response_text.strip()\n",
    "            # Remove markdown code blocks if present\n",
    "            cleaned_text = re.sub(r'```json|```', '', cleaned_text)\n",
    "            \n",
    "            # Attempt to parse again\n",
    "            try:\n",
    "                result = json.loads(cleaned_text)\n",
    "                return result\n",
    "            except:\n",
    "                print(f\"Failed to parse JSON from response: {response_text}\")\n",
    "                # Return a structured empty result\n",
    "                return {\"questions\": []}\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting Q&A: {e}\")\n",
    "        return {\"questions\": []}\n",
    "\n",
    "def process_files_and_extract_qa(file_path):\n",
    "    \"\"\"Processes all pages and extracts chemistry Q&A for each page.\"\"\"\n",
    "    page_data = process_files(file_path)\n",
    "    all_questions = []\n",
    "\n",
    "    for i, page in enumerate(page_data):\n",
    "        print(f\"Processing page {i+1}/{len(page_data)}...\")\n",
    "        qa_data = extract_chemistry_qa_from_page(page[\"data\"])\n",
    "        \n",
    "        if qa_data and \"questions\" in qa_data and qa_data[\"questions\"]:\n",
    "            for q in qa_data[\"questions\"]:\n",
    "                q[\"page_number\"] = page[\"page_number\"]\n",
    "                q[\"page_type\"] = page[\"page_type\"]\n",
    "                all_questions.append(q)\n",
    "\n",
    "    print(f\"Extracted {len(all_questions)} questions total.\")\n",
    "    return all_questions\n",
    "\n",
    "def store_qa_in_db(questions):\n",
    "    \"\"\"Stores the Q&A data in the vector database.\"\"\"\n",
    "    for i, q in enumerate(questions):\n",
    "        # Prepare data for embedding\n",
    "        question_id = f\"q{i+1}\"\n",
    "        \n",
    "        # Create full text representation for embedding\n",
    "        full_text = f\"Question: {q['question_text']}\\n\"\n",
    "        \n",
    "        if \"options\" in q:\n",
    "            options_text = \"\"\n",
    "            for option_key, option_text in q[\"options\"].items():\n",
    "                options_text += f\"Option {option_key}: {option_text}\\n\"\n",
    "            full_text += options_text\n",
    "        \n",
    "        if \"correct_answer\" in q:\n",
    "            full_text += f\"Correct Answer: {q['correct_answer']}\\n\"\n",
    "        \n",
    "        if \"explanation\" in q:\n",
    "            full_text += f\"Explanation: {q['explanation']}\\n\"\n",
    "        \n",
    "        # Generate embeddings\n",
    "        embedding = embedding_model.encode(full_text).tolist()\n",
    "        \n",
    "        # Store in Chroma\n",
    "        collection.add(\n",
    "            embeddings=[embedding],\n",
    "            documents=[full_text],\n",
    "            metadatas=[{\n",
    "                \"page_number\": q.get(\"page_number\", 0),\n",
    "                \"page_type\": q.get(\"page_type\", \"unknown\"),\n",
    "                \"question_id\": question_id\n",
    "            }],\n",
    "            ids=[question_id]\n",
    "        )\n",
    "        \n",
    "        print(f\"Stored question {i+1} in database with ID {question_id}\")\n",
    "\n",
    "def query_qa_db(query, n_results=5):\n",
    "    \"\"\"Queries the chemistry Q&A vector database and returns relevant results.\"\"\"\n",
    "    query_embedding = embedding_model.encode(query).tolist()\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding],\n",
    "        n_results=n_results\n",
    "    )\n",
    "    return results\n",
    "\n",
    "def generate_answer(user_query, retrieved_results):\n",
    "    \"\"\"Generates an answer using Gemini based on retrieved results.\"\"\"\n",
    "    # Compile context from retrieved documents\n",
    "    context_docs = retrieved_results[\"documents\"][0] if retrieved_results[\"documents\"] else []\n",
    "    context = \"\\n\\n\".join(context_docs)\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Based on the following chemistry question and answer information, provide a detailed answer to the user's query.\n",
    "    \n",
    "    Retrieved Information:\n",
    "    {context}\n",
    "    \n",
    "    User Query: {user_query}\n",
    "    \n",
    "    Provide a clear, detailed answer with explanations of the chemistry concepts involved. If the answer involves chemical reactions, explain the mechanism where appropriate.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text\n",
    "\n",
    "def rag_pipeline(user_query, n_results=3):\n",
    "    \"\"\"Full RAG pipeline: Retrieval + Answer Generation.\"\"\"\n",
    "    print(f\"Processing query: {user_query}\")\n",
    "    \n",
    "    # Retrieve relevant Q&A content\n",
    "    retrieved_results = query_qa_db(user_query, n_results)\n",
    "    \n",
    "    # Generate answer based on retrieved content\n",
    "    answer = generate_answer(user_query, retrieved_results)\n",
    "    \n",
    "    return answer\n",
    "\n",
    "# Example usage\n",
    "def main():\n",
    "    # Path to the chemistry PDF\n",
    "    file_path = \"chem.pdf\"  # Change to your file\n",
    "    \n",
    "    # Step 1: Process the PDF and extract Q&A data\n",
    "    print(\"Extracting questions and answers from PDF...\")\n",
    "    questions = process_files_and_extract_qa(file_path)\n",
    "    \n",
    "    # Step 2: Store the Q&A data in the vector database\n",
    "    print(\"Storing Q&A data in the vector database...\")\n",
    "    store_qa_in_db(questions)\n",
    "    \n",
    "    # Step 3: Use the RAG pipeline to answer questions\n",
    "    print(\"\\nRAG pipeline ready! You can now ask chemistry questions.\")\n",
    "    print(\"Example queries:\")\n",
    "    print(\"- What is the mechanism for alkene bromination?\")\n",
    "    print(\"- How do Grignard reagents form?\")\n",
    "    print(\"- What is the difference between SN1 and SN2 reactions?\")\n",
    "    \n",
    "    while True:\n",
    "        user_query = \"What is Grignard reagent?\"  # Change to your query\n",
    "        if user_query.lower() == 'exit':\n",
    "            break\n",
    "        \n",
    "        answer = rag_pipeline(user_query)\n",
    "        print(\"\\nAnswer:\")\n",
    "        print(answer)\n",
    "        break\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
